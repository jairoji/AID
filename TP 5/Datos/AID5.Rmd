---
title: "TP 5 AID"
author: "Jairo Jiménez"
date: "30 de junio de 2015"
output: html_document
---

##Cargando librerías
```{r}
library(readxl)   #Para leer los archivos de excel
library(psych)    #Para calcular las estadísticas por grupo
library(ggplot2)  #Para graficar
library(nortest)  #Para hacer las pruebas de hipótesis de normalidad
library(lawstat)  #Prueba de Levene
library(reshape)  #Manejo de datos
```

```{r, echo = F}
Normalidad.fun = function(x){
  Pruebas.Normalidad = matrix(c(ad.test(x)$p.value, shapiro.test(x)$p.value,
  lillie.test(x)$p.value, cvm.test(x)$p.value), ncol = 1)
  rownames(Pruebas.Normalidad) = c("Anderson-Darling", "Shapiro-Wilks",
                                   "Lilliefors", "Cramer Von Misses")
  colnames(Pruebas.Normalidad) = "Valor p"
  return(Pruebas.Normalidad)
}

Homocedasticidad.fun = function(x, y){
  Pruebas.Homocedasticidad = matrix(c(bartlett.test(x, y)$p.value,
  levene.test(x, y)$p.value), ncol = 1)
  rownames(Pruebas.Homocedasticidad) = c("Bartlett", "Levene")
  colnames(Pruebas.Homocedasticidad) = "Valor p"
  return(Pruebas.Homocedasticidad)
}

```


## Ejercicio 1

Un investigador estudió el contenido en sodio de las marcas de cerveza comercializadas en Capital Federal y Gran Buenos Aires. Para ello, selecciono las 6 marcas más prestigiosas del mercado y eligió botellas o latas de 500ml de cada marca seleccionada y midió el contenido en sodio (en miligramos) de cada una de ellas. Los resultados de este muestreo fueron los siguientes:


####Lectura de los datos
```{r}
Cerveza = read_excel("cerveza.xls")
names(Cerveza) = c("Sodio", "Marca", "Promedio_Marca", "Res.med")
head(Cerveza)
```

####a) Graficar la variable observada en los grupos y analizar la presencia de outliers y la igualdad grafica de las medias y las formas de las distribuciones.
```{r}
ggplot(data = Cerveza, aes(x = Marca, y = Sodio, fill = Marca)) + geom_boxplot()
```

* Las marcas que presentan valores atípicos son las marcas 3 y 6.
* En el gráfico hay una diferencia notable entre las medias de cada una de las marcas.
* Las distribuciones son sesgadas para las marcas 1, 2 y 5. Para las marcas 3, 4 y 6, las distribuciones parecen ser simétricas, lo que indica diferencias en las varianzas.

####b) Calcular la media y el desvio de cada uno de los grupos. ¿Le parece que se satisface el supuesto de homogeneidad?
```{r}
describeBy(Cerveza$Sodio, group = Cerveza$Marca, mat = T)[,c("group1", "mean", "sd")]
```

Al parecer no se satisface el supuesto de homogeneidad, pues las varianzas son muy diferentes entre sí.

####c) Establecer las hipótesis estadísticas de interés.
* Hipótesis nula: 

Los promedios de contenido de sodio en cada una de las marcas son iguales:

$H_0: \mu_1 = \mu_2 = \dots = \mu_n = \mu$ 

* Hipótesis alternativa:

Existe al menos un promedio de contenido de sodio que es diferente de los demás

$H_a: \exists \mu_i \neq \mu$, $i = 1, \dots , n$

####d) Contrastar las hipótesis con un nivel $\alpha$ = 0.05.
```{r}
(Cerveza.AOV = aov(data = Cerveza, Sodio ~ Marca))
summary(Cerveza.AOV)
```

Se añade la columna de residuales a la matriz de datos de cerveza para su uso posterior en las pruebas de homocedasticidad.

```{r}
Cerveza = cbind(Cerveza, residuals(Cerveza.AOV))
colnames(Cerveza)[5] = "Anova.Residuales"
```

Existe evidencia estadística para rechazar la hipótesis nula con un valor $\alpha = 0.05$, es decir, las medias son diferentes. Es necesario analizar los supuestos de la prueba antes de concluir.

####e) Verificar el cumplimiento de los supuestos de normalidad y homocedasticidad.
Para verificar el supuesto de normalidad se usan las siguientes pruebas:

* Anderson-Darling
```{r}
ad.test(Cerveza$Anova.Residuales)
```

* Lilliefors (Kolmogorov-Smirnov)
```{r}
lillie.test(Cerveza$Anova.Residuales)
```


* Shapiro-Wilks
```{r}
shapiro.test(Cerveza$Anova.Residuales)
```

* Cramer Von Misses
```{r}
cvm.test(Cerveza$Anova.Residuales)
```

* Gráfico Cuantil-Cuantil
```{r}
qqnorm(Cerveza$Anova.Residuales)
qqline(Cerveza$Anova.Residuales)
```


No existe suficiente evidencia estadística para rechazar la hipótesis de normalidad en los residuales del modelo con ninguno de los test presentados anteriormente.

Para verificar la hipótesis de homocedasticidad de los datos, se usan los siguientes test:

* Test de Levene
```{r}
levene.test(Cerveza$Anova.Residuales, Cerveza$Marca)
```

* Test de Bartlett
```{r}
bartlett.test(Cerveza$Anova.Residuales, Cerveza$Marca)
```

No existe evidencia estadística para rechazar la hipótesis de homocedasticidad.

####f) Si se verifican, concluir en el contexto del problema.
Como las hipótesis de la anova se satisfacen, se concluye que existen diferencias en las medias de los datos presentados.

```{r}
TukeyHSD(Cerveza.AOV)
```

De acuerdo a la prueba de Tukey, las únicas marcas que no presentan diferencias significativas son las marcas 3 y 6, es decir, estas contienen contenidos similares de sodio, mientras que las demás no.

##Ejercicio 2
Para comparar cuatro suplementos “de engorde” en bovinos para carne, se seleccionaron, al azar, cuarenta animales Hereford de iguales edad y sexo, y de pesos homogéneos para ser usados en un experimento.

Suplemento 1 (S1) estuvo constituido por grano partido y fuente A.

Suplemento 2 (S2) por grano partido y fuente B.

Suplemento 3 (S3) por grano entero y fuente A.

Suplemento 4 (S4) por grano entero y fuente B.

Se asignaron aleatoriamente 10 animales por suplemento, los que fueron alimentados individualmente con una dieta estándar más el correspondiente suplemento durante 80 días. La variable en estudio (o respuesta) fue la eficiencia de conversión (EfCon) individual (kg Materia Seca/ kg Ganancia de Peso) cuyos registros se presentan en la siguiente tabla:


```{r, echo = F}
Datos = c(3.3, 4.6, 6.7, 6.3, 4.4, 4.5, 5.8, 6.0, 4.9, 5.0, 5.0, 6.7, 4.9, 4.0, 4.8, 5.5, 3.9, 4.5, 5.3, 6.6, 4.2, 5.2, 6.2, 6.1, 4.7, 4.9, 5.0, 5.3, 5.1, 5.5, 6.4, 6.5, 4.6, 4.8, 5.9, 6.3, 4.5, 5.3, 5.4, 6.8)
Datos = matrix(Datos, ncol = 4, byrow = T )
colnames(Datos) = c("S1", "S2", "S3", "S4")
head(Datos)
```

####a) Realice un análisis gráfico y descriptivo de la eficiencia de conversión lograda por los distintos suplementos.

```{r, echo = F}
Datos.Formato1 = melt(Datos)
Datos.Formato1 = Datos.Formato1[,-1]
colnames(Datos.Formato1) = c("Suplemento", "EfCon")
```

Boxplots para cada uno de los tratamientos:

```{r, echo = F}
ggplot(data = Datos.Formato1, aes(y = EfCon, x = Suplemento, fill = Suplemento)) + geom_boxplot()
```

Los suplementos S1, S2 y S4 parecen ser similares entre ellos, pero es posible que no haya igualdad de medias en este caso porque el suplemento 3 difiere mucho del resto.

Cálculo de los promedios y las desviaciones estandar para cada uno de los tratamientos:

```{r, echo = F}
describeBy(Datos.Formato1$EfCon, Datos.Formato1$Suplemento, mat =T)[,c("group1", "mean", "sd")]
```

Las desviaciones estandar presentadas verifican lo dicho anteriormente sobre los suplementos S1, S2 y S4. Se sigue notando que el suplemento S4 es diferente de los demás.

####b) Establezca las hipótesis de interés del problema y explicite los supuestos necesarios.

* Hipótesis nula: 

Los promedios de eficiencia de conversión para los suplementos son iguales.

$H_0: \mu_1 = \mu_2 = \dots = \mu_n = \mu$ 

* Hipótesis alternativa:

Existe al menos un promedio de eficiencia de conversión que es diferente de los demás.

$H_a: \exists \mu_i \neq \mu$, $i = 1, \dots , n$

####c) Testee las hipótesis al 5%.
```{r, echo = F}
Datos.Formato1.AOV = aov(data = Datos.Formato1, EfCon ~ Suplemento)
summary(Datos.Formato1.AOV)
Datos.Formato1 = cbind(Datos.Formato1, residuals(Datos.Formato1.AOV))
colnames(Datos.Formato1)[ncol(Datos.Formato1)] = "Residuales"
# head(Datos.Formato1)
```

El análisis de varianza rechaza la hipótesis de igualdad en el promedio de eficiencia de conversión para cada uno de los suplementos, falta verificar que se cumplen los supuestos para poder concluir los resultados.

####d) Analice el cumplimiento de los supuestos del modelo.

```{r, echo = F}
Normalidad.fun(Datos.Formato1$Residuales)
```

Ninguna de las pruebas de normalidad rechaza la hipótesis nula, es decir, se puede asumir que los residuales del modelo tienen distribución normal.

```{r, echo = F}
Homocedasticidad.fun(Datos.Formato1$Residuales, Datos.Formato1$Suplemento)
```

Las pruebas de homocedasticidad tampoco rechazan la hipótesis nula en este caso, por lo tanto se puede asumir que las varianzas de los residuales son iguales para cada uno de los suplementos.

####e) Concluya en términos del problema y si rechazó $H_0$, indique cuales medias son diferentes. Utilice para ello las comparaciones a posteriori de Tuckey.

```{r, echo = F}
TukeyHSD(Datos.Formato1.AOV)
```

Se conluye que hay diferencias entre los promedios de eficiencia de conversión en los suplementos. La prueba de Tukey nos permite concluir que las diferencias están dadas por el grano partido y el grano entero, pues los suplementos S1 y S2 que están constituidos por grano partido no presentan diferencias entre ellos al igual que los suplementos S3 y S4 que están constituidos por grano entero.

##Ejercicio 3
Se desea estudiar el efecto de una nueva droga analgésica para uso farmacéutico en pacientes con neuralgia crónica. Para ello se la compara con la aspirina y un placebo. En 30 pacientes elegidos al azar, se utiliza el método del doble ciego, asignando al azar 10 pacientes a cada tratamiento. La v.a. observada es el número de horas en que el paciente está libre de dolor después de haber sido tratado. Los resultados obtenidos fueron:

```{r, echo = F}
Datos = matrix(c(2.50, 0.13, 2.82, 0.20, 3.20, 0.17), ncol = 2, byrow = T)
colnames(Datos) = c("Media", "Desviación")
rownames(Datos) = c("Placebo", "Aspirina", "Droga")
Datos
```

####1.  Identifique la variable dependiente y el factor de interes.

La variable dependiente en el modelo es el número de horas en el que el paciente está libre de dolor después de haber sido tratado por el tratamiento (Factor)

####2.  Escriba el modelo, en general y en términos del problema.

Sean:

* $Y_{ij}:$ Representa la $j$-ésima observación en el tratamiento $i$

* $\mu:$ Intercepto del modelo

* $\tau_i:$ Tratamiento $i$

* $\epsilon_{ij}:$ Residual del individuo $j$ en el tratamiento $i$

El modelo general está dado por $Y_{ij} = \mu + \tau_i +\epsilon_{ij}$

En este ejercicio, $Y_{ij}$ es el número de horas en el que el paciente está libre de dolor después de haber sido tratado, y $\tau_i$ es el tratamiento.

####3.  Analice los resultados de las pruebas de hipótesis para los supuestos del modelo.
Supuestos del modelo: 

* Prueba de Levene: p = 0.18; 

* Prueba de Shapiro - Wilk con los residuos: p= 0,24

En ninguno de los dos casos se rechaza la respectiva hipótesis nula, es decir, se puede asumir que los residuales son homocedásticos y tienen distribución normal.

####4.  Plantee las hipótesis y construya la tabla de Anova sabiendo que $$SC_{error} = \sum (n_i -1) s_i^2 $$

```{r, echo = F}
X.bar = (10*sum(Datos[,"Media"]))/30
SSB = 10*sum((Datos[,"Media"]-X.bar)^2)/2
S_p = sum(Datos[,"Desviación"])*9/27
estadistico.F = SSB/S_p
```

Los valores obtenidos son:

* $SSB$ = `r round(SSB, 3)`

* $S_p^2$ = `r round(S_p, 3)`

* $F^{obs}$ = `r round(estadistico.F, 3)`

* $F_{2,27, 0.05}$ = `r round(qf(.95, 2, 27), 3)`

Como $F^{obs} > F_{2,27, 0.05}$, se rechaza la hipótesis nula.

####5.  Compare los tratamientos utilizando un test t con nivel global 0.05 es decir que como son 3 comparaciones $\alpha = \frac{0.05}{3}$ para cada una.

```{r, echo = F}
Prueba.t = function(D1, D2, n1, n2, alfa){
  m1 = D1["Media"]
  m2 = D2["Media"]
  sd1 = D1["Desviación"]
  sd2 = D2["Desviación"]
  gl = (n1+n2-2)
  s_a2 = (((n1-1)*sd1^2)+ ((n2-1)*sd2^2))/gl
  valor.t = abs(m1-m2)/sqrt(s_a2*(n1+n2)/(n1*n2))
  dist.t = qt(1-alfa, gl)
  h = ifelse(valor.t > dist.t, "Rechazo", "No rechazo")
  names(h) = NULL
  Resultado.p = as.data.frame(matrix(c(round(valor.t, 4), round(dist.t, 4), round(alfa, 4)), nrow = 1))
  colnames(Resultado.p) = c("Valor observado", "Valor teórico t", "Alfa")
  Resultado = list(Resultado = Resultado.p, Decision = h)
  return(Resultado)
}
```

Placebo vs Aspirina

```{r, echo = F}
Prueba.t(Datos["Placebo", ], Datos["Aspirina", ], 10, 10, 0.05/3)
```

Placebo vs Droga

```{r, echo = F}
Prueba.t(Datos["Placebo", ], Datos["Droga", ], 10, 10, 0.05/3)
```

Droga vs Aspirina

```{r, echo = F}
Prueba.t(Datos["Droga", ], Datos["Aspirina", ], 10, 10, 0.05/3)
```

####6.  Adicionalmente se indagó a los pacientes sobre efectos colaterales gástricos como respuesta al tratamiento. Los encuestados respondieron según una escala entre 0 y 5 (0 = nunca, 5= siempre). Los resultados obtenidos fueron:

```{r, echo = F}
Tabla = matrix(c(0, 3, 2, 3, 4, 2, 2, 3, 1, 1, 1, 4, 3, 0, 2, 3, 4, 5, 2, 3, 4, 5, 4, 2, 3, 4, 1, 5, 3, 0), nrow = 3, byrow = T)
rownames(Tabla) = c("Placebo", "Aspirina", "Droga")
Tabla
```
####6.1 ¿Cree que los investigadores deberían utilizar la misma prueba estadística que la empleada para comparar el tiempo libre de dolor? Justifique.

No, en este caso no es viable hacer un análisis de varianza pues los datos que se están trabajando son de tipo categórico.

####6.2 ¿Cuáles son las conclusiones de este estudio?




##Ejercicio 4

Se está estudiando el tiempo de cocción de un alimento antes de lanzarlo al mercado. Se han formado cuatro grupos y se les ha pedido que midan el tiempo transcurrido hasta que, según su juicio, el alimento quede a punto. Como esta sensación es subjetiva, se usa un ANOVA para estimar la varianza que presenta el experimento. Todos los grupos usan fuentes de calor y utensilios similares. Si la tabla siguiente recoge los resultados redondeados en minutos, ¿qué estimación podríamos hacer de la varianza de la población de estos alimentos? ¿Se observan diferencias entre los grupos?

```{r, echo = F}
Datos = matrix(c(25, 121, 81, 25, 36, 36, 81, 25, 36, 36, 36, 36, 25, 64, 9, 25, 36, 36, 25, 36, 16, 81, 36, 25, 25, 49, 9, 25, 36, 25, 49, 25, 49, 64, 169, 25, 36, 49, 1, 25, 25, 121, 81, 25), ncol = 4, byrow = T)
colnames(Datos) = c("Grupo A", "Grupo B", "Grupo C", "Grupo D")
Datos.Transformados1 = melt(Datos)[,-1]
colnames(Datos.Transformados1) = c("Grupo", "Tiempo")
Datos
```

####a) Grafique los tiempos de cocción por tratamiento. Calcule las medidas resumen de los mismos.

```{r, echo = F}
ggplot(Datos.Transformados1, aes(x = Grupo, y = Tiempo, fill = Grupo)) + geom_boxplot()
```

```{r, echo = F}
(resumen.4 = describeBy(Datos.Transformados1$Tiempo, Datos.Transformados1$Grupo, mat = T)[,c("group1", "mean", "sd")])
```

Por el gráfico y los valores obtenidos de media y desviación estandar para cada uno de los grupos, parece haber diferencias en la media entre los grupos.

####b) Establezca las hipótesis de interés, escriba el modelo detallando los supuestos.

* Hipótesis nula: 

Los promedios de los tiempos de cocción para cada uno de los grupos son iguales:

$H_0: \mu_1 = \mu_2 = \dots = \mu_n = \mu$ 

* Hipótesis alternativa:

Existe al menos un promedio de tiempo de cocción que es diferente de los demás:

$H_a: \exists \mu_i \neq \mu$, $i = 1, \dots , n$

Sean:

* $Y_{ij}:$ Representa la $j$-ésima observación en el tratamiento $i$

* $\mu:$ Intercepto del modelo

* $\tau_i:$ Tratamiento $i$

* $\epsilon_{ij}:$ Residual del individuo $j$ en el tratamiento $i$

El modelo general está dado por $Y_{ij} = \mu + \tau_i +\epsilon_{ij}$

En este ejercicio, $Y_{ij}$ es el tiempo de cocción de cada alimento en cada grupo, y $\tau_i$ representa cada uno de los grupos.

Además, la distribución los residuales $\epsilon_{ij}$ es normal y con varianza igual para todos los grupos (Homocedástico).

####c) Realice la prueba y el diagnostico correspondiente. ¿Son válidos los resultados de la prueba?

```{r, echo = F}
Datos.Transformados.AOV = aov(data = Datos.Transformados1, Tiempo ~ Grupo)
Datos.Transformados1 = cbind(Datos.Transformados1, residuals(Datos.Transformados.AOV))
colnames(Datos.Transformados1)[ncol(Datos.Transformados1)] = "Residuales"
summary(Datos.Transformados.AOV)
```

Pruebas de normalidad
```{r, echo = F}
Normalidad.fun(Datos.Transformados1$Residuales)
```

Pruebas de homocedasticidad
```{r, echo = F}
Homocedasticidad.fun(Datos.Transformados1$Residuales, Datos.Transformados1$Grupo)
```

En este caso se rechaza la hipótesis de igualdad de medias, es decir, los promedios de los tiempos de cocción en los grupos no son iguales, sin embargo, no se satisfacen las hipótesis del análisis de varianza, por lo tanto el test no es conclusivo.

####d) Si respondió afirmativamente en c) concluya en el contexto del problema. Si concluyo negativamente intente una transformación de potencia conveniente para normalizar y/o homocedastizar la variable respuesta.

```{r, width=150, height=300}
ggplot(resumen.4, aes(x=mean, y=sd)) +geom_point()
```


En este caso, la transformación que parece ser más adecuada por el tipo de datos que se están trabajando es la transformación raíz cuadrada, con la cual se calcula el siguiente análisis de varianza:

```{r, echo = F}
# 0.3512941
Datos.Transformados1 = cbind(Datos.Transformados1, (Datos.Transformados1[["Tiempo"]])^(0.5))
colnames(Datos.Transformados1)[ncol(Datos.Transformados1)] = "Transformados"
Datos.Transformados.AOV = aov(data = Datos.Transformados1, Transformados ~ Grupo)
summary(Datos.Transformados.AOV)
```



Como el valor p es menor al valor alfa establecido, se rechaza la hipótesis nula nuevamente, sin embargo, falta verificar los supuestos:


####e) Realice nuevamente la prueba si fuera necesario y el diagnóstico del modelo correspondiente. Concluya en términos del problema.

Normalidad

```{r, echo = F}
Datos.Transformados1 = cbind(Datos.Transformados1, residuals(Datos.Transformados.AOV))
colnames(Datos.Transformados1)[ncol(Datos.Transformados1)] = "Residuales.Transformados"
Normalidad.fun(Datos.Transformados1$Residuales.Transformados)
```

Homocedasticidad

```{r, echo = F}
Homocedasticidad.fun(Datos.Transformados1$Residuales.Transformados, Datos.Transformados1$Grupo)
# levene.test(Datos.Transformados1$Residuales.Transformados, Datos.Transformados1$Grupo)
# head(Datos.Transformados1)
```

En todos los casos se rechazan las hipótesis normalidad y homocedasticidad en los residuales del modelo, lo cual invalida el test presentado anteriormente. Se propone hacer una prueba no paramétrica de igualdad de medias.


####f) Compare los resultados con los del test no paramétrico.

El test no paramétrico a realizar es el test de Kruskal-Wallis basado en rangos, con el cual se obtiene;

```{r, echo = F}
kruskal.test(Tiempo ~ Grupo, data = Datos.Transformados1)
```

El valor p obtenido es menor al valor de alfa establecido, por lo tanto, se rechaza la hipótesis de igualdad de medias. 

En los análisis de varianzas realizados, se rechazó la hipótesis nula de igualdad para los datos originales y para los datos transformados, sin embargo, los test nunca fueron concluyentes porque en ninguno de los casos se cumplieron los supuestos de normalidad y homocedasticidad. El test no paramétrico logra mostrar que existen diferencias en las medias de los grupos.

##Ejercicio 5
Se quiere comparar el trabajo de cuatro analistas de un laboratorio en el ensayo de determinación del % de alcohol metílico en muestras de un producto químico, mediante la técnica de cromatografía líquida de alta resolución (HPLC). Los analistas reportaron los resultados siguientes:


```{r, echo = F}
Datos = matrix(c(84.99, 84.02, 84.38, 85.15, 85.13, 84.88, 84.72, 84.48, 85.16, 84.2, 84.1, 84.55), nrow = 4, byrow = T)
rownames(Datos) = c("Analista 1", "Analista 2", "Analista 3", "Analista 4")
# colnames(Datos) = c("Muestra_1", "Muestra_2", "Muestra_3")
datos.melt = melt(t(Datos))[-1]
colnames(datos.melt) = c("Analista", "Porcentaje_Alcohol")
Datos
```

####a) ¿Por qué no es adecuado aplicar en este caso el análisis de la varianza paramétrico?

Para el análisis de varianza paramétrico se debe satisfacer el supuesto de normalidad en los residuales, sin embargo, las pruebas existentes son sensibles cuando se tienen muchos o muy pocos datos. [Ver R Bloggers](http://www.r-bloggers.com/normality-tests-don%E2%80%99t-do-what-you-think-they-do/)

####b) Mediante la prueba no paramétrica de Kruskall-Wallis, determinar si el % depende del analista.

```{r, echo = F}
kruskal.test(Porcentaje_Alcohol ~ Analista, data = datos.melt)
```

Como el valor p obtenido es menor a $\alpha = 0.05$%, no existe evidencia estadística para rechazar la hipótesis de igualdad de medias, es decir, el porcentaje de alcohol no depende del analista.

